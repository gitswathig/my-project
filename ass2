pip install xgboost
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, roc_curve, roc_auc_score
data = pd.read_csv('dataset.csv')
data.head(10)
data.describe()
data.info()
categorical_cols = ['Sex', 'Diet', 'Country', 'Continent', 'Hemisphere']
for col in categorical_cols:
    data[col] = LabelEncoder().fit_transform(data[col])
data.isnull().sum()
data = data.drop('Patient ID', axis=1)
plt.figure(figsize=(8, 7))
for col in categorical_cols:
    sns.countplot(data=data, x=col)
    plt.show()
bp_split = data['Blood Pressure'].str.split('/', expand=True)
data['BP_Systolic'] = pd.to_numeric(bp_split[0], errors='coerce').fillna(0).astype(int)
data['BP_Diastolic'] = pd.to_numeric(bp_split[1], errors='coerce').fillna(0).astype(int)
data.drop('Blood Pressure', axis=1, inplace=True)
plt.figure(figsize=(19, 10))
sns.heatmap(data.corr(), cmap="YlGnBu", annot=True)
plt.show()
plt.figure(figsize=(12, 6))
sns.boxplot(x='Heart Attack Risk', y='Age', data=data)
plt.title('Age vs. Heart Attack Risk')
plt.show()
plt.figure(figsize=(12, 6))
sns.boxplot(x='Heart Attack Risk', y='Cholesterol', data=data)
plt.title('Cholesterol vs. Heart Attack Risk')
plt.show()
X = data.drop('Heart Attack Risk', axis=1)
y = data['Heart Attack Risk']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision'])
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'XGBoost': xgb.XGBClassifier(),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier(),
    'Gaussian Naive Bayes': GaussianNB()
}
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    predictions = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, predictions)
    precision = precision_score(y_test, predictions, zero_division=1)
    print(f'{name} - Accuracy: {accuracy}, Precision: {precision}')
    new_row = {'Model': name, 'Accuracy': accuracy, 'Precision': precision}
    results_df = pd.concat([results_df, pd.DataFrame([new_row])])
rf_model = RandomForestClassifier()
rf_model.fit(X_train_scaled, y_train)
rf_predictions = rf_model.predict(X_test_scaled)
fpr, tpr, thresholds = roc_curve(y_test, rf_predictions)
roc_auc = roc_auc_score(y_test, rf_predictions)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()
plt.figure(figsize=(12, 6))

# Accuracy ve Precision için iki ayrı çubuk grafik çizin
plt.subplot(1, 2, 1)
sns.barplot(x='Model', y='Accuracy', data=results_df)
plt.title('Accuracy by Model')

plt.subplot(1, 2, 2)
sns.barplot(x='Model', y='Precision', data=results_df)
plt.title('Precision by Model')

plt.tight_layout()
plt.show()
print(results_df.columns)
for name, row in results_df.iterrows():
    print(f'{name} - Model: {row["Model"]}, Accuracy: {row["Accuracy"]}, Precision: {row["Precision"]}')
